static sg_ioctl(struct file *filp, unsigned int cmd_in, unsigned long arg) void __user * p = ( void __user * ) arg ; int __user * ip = p ; int result , val , read_only ; Sg_device * sdp ; Sg_fd * sfp ; Sg_request * srp ; if ( ( ! ( sfp = ( Sg_fd * ) filp -> private_data ) ) || ( ! ( sdp = sfp -> parentdp ) ) )  read_only = ( O_RDWR != ( filp -> f_flags & O_ACCMODE ) ); switch ( cmd_in )  if ( atomic_read ( & sdp -> detaching ) )  if ( ! scsi_block_when_processing_errors ( sdp -> device ) )  if ( ! access_ok ( VERIFY_WRITE , p , SZ_SG_IO_HDR ) )  result = sg_new_write ( sfp , filp , p , SZ_SG_IO_HDR , 1 , read_only , 1 , & srp ); if ( result < 0 )  result = wait_event_interruptible ( sfp -> read_wait , ( srp_done ( sfp , srp ) || atomic_read ( & sdp -> detaching ) ) ); result = get_user ( val , ip ); if ( result )  if ( val < 0 )  if ( val >= MULDIV ( INT_MAX , USER_HZ , HZ ) )  val = MULDIV ( INT_MAX , USER_HZ , HZ ); sfp -> timeout_user = val; sfp -> timeout = MULDIV ( val , HZ , USER_HZ ); result = get_user ( val , ip ); if ( result )  if ( val )  sfp -> low_dma = 1; if ( ( 0 == sfp -> low_dma ) && ( 0 == sg_res_in_use ( sfp ) ) )  val = ( int ) sfp -> reserve . bufflen; if ( atomic_read ( & sdp -> detaching ) )  sfp -> low_dma = sdp -> device -> host -> unchecked_isa_dma; result = get_user ( val , ip ); if ( result )  sfp -> force_packid = val ? 1 : 0; result = get_user ( val , ip ); if ( result )  if ( val < 0 )  val = min_t ( int , val , max_sectors_bytes ( sdp -> device -> request_queue ) ); if ( val != sfp -> reserve . bufflen )  if ( sg_res_in_use ( sfp ) || sfp -> mmap_called )  sg_build_reserve ( sfp , val ); static sg_build_reserve(Sg_fd * sfp, int req_size) Sg_scatter_hold * schp = & sfp -> reserve ; if ( req_size < PAGE_SIZE )  req_size = PAGE_SIZE; if ( 0 == sg_build_indirect ( schp , sfp , req_size ) )  sg_remove_scat ( sfp , schp ); req_size >>= 1; while ( req_size > ( PAGE_SIZE / 2 ) )  static sg_remove_scat(Sg_fd * sfp, Sg_scatter_hold * schp) memset ( schp , 0 , sizeof ( * schp ) ); 