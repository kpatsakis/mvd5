static sg_ioctl(struct file *filp, unsigned int cmd_in, unsigned long arg) void __user * p = ( void __user * ) arg ; int __user * ip = p ; int result , val , read_only ; Sg_device * sdp ; Sg_fd * sfp ; Sg_request * srp ; if ( ( ! ( sfp = ( Sg_fd * ) filp -> private_data ) ) || ( ! ( sdp = sfp -> parentdp ) ) )  read_only = ( O_RDWR != ( filp -> f_flags & O_ACCMODE ) ); switch ( cmd_in )  if ( atomic_read ( & sdp -> detaching ) )  if ( ! scsi_block_when_processing_errors ( sdp -> device ) )  if ( ! access_ok ( VERIFY_WRITE , p , SZ_SG_IO_HDR ) )  result = sg_new_write ( sfp , filp , p , SZ_SG_IO_HDR , 1 , read_only , 1 , & srp ); if ( result < 0 )  result = wait_event_interruptible ( sfp -> read_wait , ( srp_done ( sfp , srp ) || atomic_read ( & sdp -> detaching ) ) ); result = get_user ( val , ip ); if ( result )  if ( val < 0 )  if ( val >= MULDIV ( INT_MAX , USER_HZ , HZ ) )  val = MULDIV ( INT_MAX , USER_HZ , HZ ); sfp -> timeout_user = val; sfp -> timeout = MULDIV ( val , HZ , USER_HZ ); result = get_user ( val , ip ); if ( result )  if ( val )  sfp -> low_dma = 1; if ( ( 0 == sfp -> low_dma ) && ( 0 == sg_res_in_use ( sfp ) ) )  val = ( int ) sfp -> reserve . bufflen; sg_build_reserve ( sfp , val ); static sg_build_reserve(Sg_fd * sfp, int req_size) Sg_scatter_hold * schp = & sfp -> reserve ; if ( req_size < PAGE_SIZE )  req_size = PAGE_SIZE; if ( 0 == sg_build_indirect ( schp , sfp , req_size ) )  static sg_build_indirect(Sg_scatter_hold * schp, Sg_fd * sfp, int buff_size) int sg_tablesize = sfp -> parentdp -> sg_tablesize ; int blk_size = buff_size , order ; gfp_t gfp_mask = GFP_ATOMIC | __GFP_COMP | __GFP_NOWARN ; if ( blk_size < 0 )  return - EFAULT ; blk_size = ALIGN ( blk_size , SG_SECTOR_SZ ); mx_sc_elems = sg_build_sgat ( schp , sfp , sg_tablesize ); static sg_build_sgat(Sg_scatter_hold * schp, const Sg_fd * sfp, int tablesize) int sg_bufflen = tablesize * sizeof ( struct page * ) ; gfp_t gfp_flags = GFP_ATOMIC | __GFP_NOWARN ; schp -> pages = kzalloc ( sg_bufflen , gfp_flags ); if ( ! schp -> pages )  return - ENOMEM ; return tablesize ; if ( mx_sc_elems < 0 )  return mx_sc_elems ; num = scatter_elem_sz; if ( sfp -> low_dma )  gfp_mask |= GFP_DMA; if ( ! capable ( CAP_SYS_ADMIN ) || ! capable ( CAP_SYS_RAWIO ) )  gfp_mask |= __GFP_ZERO; order = get_order ( num ); ret_sz = 1 << ( PAGE_SHIFT + order ); for (k = 0, rem_sz = blk_size; rem_sz > 0 && k < k++, rem_sz -= ret_sz) schp -> pages [ k ] = alloc_pages ( gfp_mask , order ); if ( ! schp -> pages [ k ] )  if ( rem_sz > 0 )  return - ENOMEM ; return 0 ; if ( -- order >= 0 )  return - ENOMEM ; sg_remove_scat ( sfp , schp ); req_size >>= 1; while ( req_size > ( PAGE_SIZE / 2 ) )  static sg_remove_scat(Sg_fd * sfp, Sg_scatter_hold * schp) memset ( schp , 0 , sizeof ( * schp ) ); 